from database_utils import DatabaseConnector
import pandas as pd
import tabula
import requests
from config import header, endpoint_number
import json
import boto3
from botocore import UNSIGNED
from botocore.config import Config


class DataExtractor:
    ''' 
    DatabaseExtractor is a class used to extract files from different data sources.
    -------
    Methods:
    -------
    read_rds_table(instance, table_name)
        Read the data from the RDS database by taking in an instance of your 
        DatabaseConnector class and the table name as an argument and return a pandas DataFrame.
    retrieve_pdf_data(link)
        Take a link to a .pdf file as an argument and return Pandas DataFrame.
    list_number_of_stores(endpoint, header)
        Take enpoint and headers as arguments and return a number of stores or response status code if connecttion is not successful. 
    retrieve_stores_data()
        Iterates through the API addresses based on the number of stores gained by list_number_of_stores, append all data and return a Pandas DataFrame.
    extract_from_s3(bucket_name, file_name, local_pwd)
        Take a bucket_name, file_name, local_pwd as arguments and download file from AWS S3 bucket.
    '''     
    def read_rds_table(self, instance, table_name):                                                 
        engine = instance.init_db_engine()                                                          # Creates the Instance of the engine to connect to RDS via DataConnector
        df = pd.read_sql_table(table_name, engine, index_col='index')                               # Creates pandas DF, index_col ='index' to have just one index col
        return df
    
    def retrieve_pdf_data(self, link):
        pdf_path = link
        df_pdf = tabula.read_pdf(pdf_path, stream=False, pages='all')                               # Extracts data from pdf and adds all pages into one tabular data file
        df_pdf = pd.concat(df_pdf)                                                                  # Returns pandas DF 
        return df_pdf

    def list_number_of_stores(self, endpoint, header):
        response = requests.get(endpoint, headers=header)                                           # Retrieves data from the API 
        if response.status_code == 200:                                                             # If responce OK, returns the number of stores 
            data = response.json()
            number = data['number_stores']
            return number
        else:
            return f'Request failed with status code: {response.status_code}'                       # If response is not OK, returns response status code

    def retrieve_stores_data(self):
        store_numbers = list(range(0, self.list_number_of_stores(endpoint_number, header)))         # Gives a list of numbers from 1 to the number of stores (451)
        # print(store_numbers)
        stores_data = []                                                                            # Empty list to append all data generated by the for loop 

        for store_number in store_numbers:                                                          # A for loop to iterate through all api addresses and gather the stores data together
            response = requests.get(f'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/{store_number}', headers=header)    # A direct link was used instead of generic argument 'endpoint' to get the store details based on the store number
            if response.status_code == 200:                                                         # If responce is OK, then all data from the loop is appened into the empty list above
                data = json.loads(response.text)
                # print(data)
                stores_data.append(data)
            else:
                print(f"Request failed with status code: {response.status_code}")                   # If responce is not OK, then prints the status code
        
        stores_df = pd.DataFrame(stores_data)                                                       # Creates pandas DF
        # stores_df.to_csv('stores_data.csv')
        return stores_df

    def extract_from_s3(self, bucket_name, file_name, local_pwd):
        s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))                          # The public acces did not work with my AWS CLI config, so unsigned configuration was used.
        s3.download_file(bucket_name, file_name, local_pwd)                                         # Instead of creating two methods that return pd dataframe from different types of files, build a generic one that just download a file. 

    
   

con = DatabaseConnector()
extractor = DataExtractor()

# extractor.read_rds_table(con, "legacy_users")
# extractor.retrieve_pdf_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf')
# extractor.list_number_of_stores(endpoint_number, header)
# extractor.retrieve_stores_data()
# extractor.extract_from_s3()


